{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of multilabel_text_classification_RuDReC.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C862xYe9FGqz",
        "colab_type": "text"
      },
      "source": [
        "## Read me\n",
        "\n",
        "This notebook is a copy of the notebook located at:\n",
        "\n",
        "https://colab.research.google.com/drive/1g_2W__vi6fuEn8pSma0NXNHbNuebptHF?usp=sharing\n",
        "\n",
        "It might be more convenient for you to follow the link and run the same notebook at Google Colab. If you run this notebook on your local machine, you have to comment out the \"%tensorflow_version 1.x\" line\n",
        "\n",
        "This notebook is an example of a multilabel sentence classification. We use RuDR-BERT, which is pretrained on the raw part of the RuDReC corpus. As a training set, we use the annotated part of the RuDReC corpus. Both data and the model are available at:\n",
        "\n",
        "https://github.com/cimm-kzn/RuDReC\n",
        "\n",
        "Please read the beginning of the section \"Downloading RuDR-BERT model\" carefully.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKN6hs1vdhRR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a3175cd7-82f7-431f-ead9-31d99eed1987"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh4lTHpvihZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "0c750f73-7666-43d8-b989-eba7fd3f4494"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jul  9 19:13:54 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90jvcmcfGQX4",
        "colab_type": "text"
      },
      "source": [
        "### Pulling necessary code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VHKWxYmdzdh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "e10543cc-f2c8-4b06-8096-f37424c0c1b5"
      },
      "source": [
        "!git init\n",
        "!git pull https://github.com/google-research/bert.git\n",
        "!git clone https://github.com/Andoree/med_project.git\n",
        "!cp med_project/multilabel_code/bert_preprocessing.py ./\n",
        "!cp med_project/multilabel_code/multilabel_bert.py ./"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized empty Git repository in /content/.git/\n",
            "remote: Enumerating objects: 340, done.\u001b[K\n",
            "remote: Total 340 (delta 0), reused 0 (delta 0), pack-reused 340\u001b[K\n",
            "Receiving objects: 100% (340/340), 317.20 KiB | 604.00 KiB/s, done.\n",
            "Resolving deltas: 100% (185/185), done.\n",
            "From https://github.com/google-research/bert\n",
            " * branch            HEAD       -> FETCH_HEAD\n",
            "Cloning into 'med_project'...\n",
            "remote: Enumerating objects: 482, done.\u001b[K\n",
            "remote: Counting objects: 100% (482/482), done.\u001b[K\n",
            "remote: Compressing objects: 100% (336/336), done.\u001b[K\n",
            "remote: Total 1865 (delta 290), reused 336 (delta 145), pack-reused 1383\u001b[K\n",
            "Receiving objects: 100% (1865/1865), 11.92 MiB | 7.34 MiB/s, done.\n",
            "Resolving deltas: 100% (543/543), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DX4rRkeo1STJ",
        "colab_type": "text"
      },
      "source": [
        "#### Downloading RuDR-BERT model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsRGenkexFyE",
        "colab_type": "text"
      },
      "source": [
        "In this tutorial, we offer 2 options:\n",
        "\n",
        "1) You can download the RuDR model that is not fine-tuned on the multilabel sentence classification task. Therefore, you need to train it on our data (annotated part of the RuDReC corpus) or another dataset.\n",
        "\n",
        "2) You can download the RuDR model that is already fine-tuned on the multilabel sentence classification task using the annotated part of RuDReC. Choosing this option, you don't need to execute cells under the \"Training\" section of this notebook. This is the same RuDReC-BERT, but it is additionally trained on the annotated part of the RuDReC corpus for 10 epochs with the batch size of 16 and max sequence length of 128.\n",
        "\n",
        "By default, the lines for the second option are commented out. If you do not want to train a model yourself, what you need is to comment download of one model and uncomment the other. Next, you need to change paths to models in the \"Parameters\" section. Change lines that correspond to the BERT model's checkpoint, vocabulary, and config.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qvd2GO2_nBb",
        "colab_type": "text"
      },
      "source": [
        "**Comment these lines out if you don't want to fine-tune RuDR-BERT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sD9FPSZViXx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "outputId": "9cea7855-beef-4e41-9ab5-492842798613"
      },
      "source": [
        "!mkdir bert_models/\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1ou6XLWI_Yp_jPwFox-QWMb3SpJIVinZp' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1ou6XLWI_Yp_jPwFox-QWMb3SpJIVinZp\" -O bert_models/RuDR_BERT.tar.gz && rm -rf /tmp/cookies.txt\n",
        "!tar -xvf bert_models/RuDR_BERT.tar.gz -C bert_models\n",
        "!ls bert_models/multilingual_russian_reviews_finetuned"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-09 19:14:13--  https://docs.google.com/uc?export=download&confirm=ltyd&id=1ou6XLWI_Yp_jPwFox-QWMb3SpJIVinZp\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.97.113, 108.177.97.100, 108.177.97.101, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.97.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-08-8s-docs.googleusercontent.com/docs/securesc/4pfs57o28d1ukb4idtk3tjp4bnavss02/7eul7mcd4jh7ooodorrffqlfommcleld/1594322025000/06930042168325031160/08233439409035204950Z/1ou6XLWI_Yp_jPwFox-QWMb3SpJIVinZp?e=download [following]\n",
            "--2020-07-09 19:14:14--  https://doc-08-8s-docs.googleusercontent.com/docs/securesc/4pfs57o28d1ukb4idtk3tjp4bnavss02/7eul7mcd4jh7ooodorrffqlfommcleld/1594322025000/06930042168325031160/08233439409035204950Z/1ou6XLWI_Yp_jPwFox-QWMb3SpJIVinZp?e=download\n",
            "Resolving doc-08-8s-docs.googleusercontent.com (doc-08-8s-docs.googleusercontent.com)... 74.125.204.132, 2404:6800:4008:c04::84\n",
            "Connecting to doc-08-8s-docs.googleusercontent.com (doc-08-8s-docs.googleusercontent.com)|74.125.204.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=c2jltnl9qdfvi&continue=https://doc-08-8s-docs.googleusercontent.com/docs/securesc/4pfs57o28d1ukb4idtk3tjp4bnavss02/7eul7mcd4jh7ooodorrffqlfommcleld/1594322025000/06930042168325031160/08233439409035204950Z/1ou6XLWI_Yp_jPwFox-QWMb3SpJIVinZp?e%3Ddownload&hash=o4ul3lfnufjh0ldmtc3v5uvt2unk0i4s [following]\n",
            "--2020-07-09 19:14:14--  https://docs.google.com/nonceSigner?nonce=c2jltnl9qdfvi&continue=https://doc-08-8s-docs.googleusercontent.com/docs/securesc/4pfs57o28d1ukb4idtk3tjp4bnavss02/7eul7mcd4jh7ooodorrffqlfommcleld/1594322025000/06930042168325031160/08233439409035204950Z/1ou6XLWI_Yp_jPwFox-QWMb3SpJIVinZp?e%3Ddownload&hash=o4ul3lfnufjh0ldmtc3v5uvt2unk0i4s\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.97.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-08-8s-docs.googleusercontent.com/docs/securesc/4pfs57o28d1ukb4idtk3tjp4bnavss02/7eul7mcd4jh7ooodorrffqlfommcleld/1594322025000/06930042168325031160/08233439409035204950Z/1ou6XLWI_Yp_jPwFox-QWMb3SpJIVinZp?e=download&nonce=c2jltnl9qdfvi&user=08233439409035204950Z&hash=hvp1svj2bi6032k6akgorpgfpcvpmdo6 [following]\n",
            "--2020-07-09 19:14:15--  https://doc-08-8s-docs.googleusercontent.com/docs/securesc/4pfs57o28d1ukb4idtk3tjp4bnavss02/7eul7mcd4jh7ooodorrffqlfommcleld/1594322025000/06930042168325031160/08233439409035204950Z/1ou6XLWI_Yp_jPwFox-QWMb3SpJIVinZp?e=download&nonce=c2jltnl9qdfvi&user=08233439409035204950Z&hash=hvp1svj2bi6032k6akgorpgfpcvpmdo6\n",
            "Connecting to doc-08-8s-docs.googleusercontent.com (doc-08-8s-docs.googleusercontent.com)|74.125.204.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/gzip]\n",
            "Saving to: ‘bert_models/RuDR_BERT.tar.gz’\n",
            "\n",
            "bert_models/RuDR_BE     [              <=>   ]   1.84G  52.4MB/s    in 40s     \n",
            "\n",
            "2020-07-09 19:14:56 (47.4 MB/s) - ‘bert_models/RuDR_BERT.tar.gz’ saved [1980987756]\n",
            "\n",
            "multilingual_russian_reviews_finetuned/\n",
            "multilingual_russian_reviews_finetuned/bert_model.ckpt.data-00000-of-00001\n",
            "multilingual_russian_reviews_finetuned/vocab.txt\n",
            "multilingual_russian_reviews_finetuned/bert_model.ckpt.index\n",
            "multilingual_russian_reviews_finetuned/description.txt\n",
            "multilingual_russian_reviews_finetuned/bert_model.ckpt.meta\n",
            "multilingual_russian_reviews_finetuned/bert_config.json\n",
            "bert_config.json\t\t     bert_model.ckpt.index  description.txt\n",
            "bert_model.ckpt.data-00000-of-00001  bert_model.ckpt.meta   vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jx77YhWA3sjj",
        "colab_type": "text"
      },
      "source": [
        "**Uncomment these lines to download the fine-tuned model** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pn9xcjfcz9ef",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "outputId": "6b0648ab-e770-40f0-83c7-6722e355a63d"
      },
      "source": [
        "# !mkdir bert_models/\n",
        "# !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1hW7QVM3iOHaWn8U31oJSF1wKfAIohCtz' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1hW7QVM3iOHaWn8U31oJSF1wKfAIohCtz\" -O bert_models/rudr_classification_finetuned.tar.gz && rm -rf /tmp/cookies.txt\n",
        "# !tar -xvf bert_models/rudr_classification_finetuned.tar.gz -C bert_models\n",
        "# !ls bert_models/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-09 19:06:32--  https://docs.google.com/uc?export=download&confirm=Xa54&id=1hW7QVM3iOHaWn8U31oJSF1wKfAIohCtz\n",
            "Resolving docs.google.com (docs.google.com)... 172.217.194.102, 172.217.194.101, 172.217.194.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.194.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0g-14-docs.googleusercontent.com/docs/securesc/ndqqiso8op3fbjmnh1125ib4jlc07qd4/nq3881kdjlnuub6nvrf1lb96ijprpsmc/1594321575000/06930042168325031160/00244358364593097285Z/1hW7QVM3iOHaWn8U31oJSF1wKfAIohCtz?e=download [following]\n",
            "--2020-07-09 19:06:32--  https://doc-0g-14-docs.googleusercontent.com/docs/securesc/ndqqiso8op3fbjmnh1125ib4jlc07qd4/nq3881kdjlnuub6nvrf1lb96ijprpsmc/1594321575000/06930042168325031160/00244358364593097285Z/1hW7QVM3iOHaWn8U31oJSF1wKfAIohCtz?e=download\n",
            "Resolving doc-0g-14-docs.googleusercontent.com (doc-0g-14-docs.googleusercontent.com)... 172.217.194.132, 2404:6800:4003:c04::84\n",
            "Connecting to doc-0g-14-docs.googleusercontent.com (doc-0g-14-docs.googleusercontent.com)|172.217.194.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=mschor6mn0ld6&continue=https://doc-0g-14-docs.googleusercontent.com/docs/securesc/ndqqiso8op3fbjmnh1125ib4jlc07qd4/nq3881kdjlnuub6nvrf1lb96ijprpsmc/1594321575000/06930042168325031160/00244358364593097285Z/1hW7QVM3iOHaWn8U31oJSF1wKfAIohCtz?e%3Ddownload&hash=ve8vk6mlehcemqve29pbothaolqeo19e [following]\n",
            "--2020-07-09 19:06:33--  https://docs.google.com/nonceSigner?nonce=mschor6mn0ld6&continue=https://doc-0g-14-docs.googleusercontent.com/docs/securesc/ndqqiso8op3fbjmnh1125ib4jlc07qd4/nq3881kdjlnuub6nvrf1lb96ijprpsmc/1594321575000/06930042168325031160/00244358364593097285Z/1hW7QVM3iOHaWn8U31oJSF1wKfAIohCtz?e%3Ddownload&hash=ve8vk6mlehcemqve29pbothaolqeo19e\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.194.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-0g-14-docs.googleusercontent.com/docs/securesc/ndqqiso8op3fbjmnh1125ib4jlc07qd4/nq3881kdjlnuub6nvrf1lb96ijprpsmc/1594321575000/06930042168325031160/00244358364593097285Z/1hW7QVM3iOHaWn8U31oJSF1wKfAIohCtz?e=download&nonce=mschor6mn0ld6&user=00244358364593097285Z&hash=2ivmujj5jk4h360m4n9admg206s7j0fc [following]\n",
            "--2020-07-09 19:06:33--  https://doc-0g-14-docs.googleusercontent.com/docs/securesc/ndqqiso8op3fbjmnh1125ib4jlc07qd4/nq3881kdjlnuub6nvrf1lb96ijprpsmc/1594321575000/06930042168325031160/00244358364593097285Z/1hW7QVM3iOHaWn8U31oJSF1wKfAIohCtz?e=download&nonce=mschor6mn0ld6&user=00244358364593097285Z&hash=2ivmujj5jk4h360m4n9admg206s7j0fc\n",
            "Connecting to doc-0g-14-docs.googleusercontent.com (doc-0g-14-docs.googleusercontent.com)|172.217.194.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/gzip]\n",
            "Saving to: ‘bert_models/rudr_classification_finetuned.tar.gz’\n",
            "\n",
            "bert_models/rudr_cl     [            <=>     ]   1.22G  46.6MB/s    in 29s     \n",
            "\n",
            "2020-07-09 19:07:03 (42.3 MB/s) - ‘bert_models/rudr_classification_finetuned.tar.gz’ saved [1308727337]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqtz3KoW1Xsw",
        "colab_type": "text"
      },
      "source": [
        "#### Downloading the annotated part of the RuDReC corpus and splitting it into senteces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-keuQK3ooJsi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "outputId": "3282f75b-1df3-4592-88da-abf4761789fe"
      },
      "source": [
        "!mkdir -p data/rudrec_annotated\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1plApL6qmdHtNNP3OXgJQEmo7Lfp6MVeO' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1plApL6qmdHtNNP3OXgJQEmo7Lfp6MVeO\" -O data/rudrec_annotated/rudrec.zip && rm -rf /tmp/cookies.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-09 19:15:50--  https://docs.google.com/uc?export=download&confirm=&id=1plApL6qmdHtNNP3OXgJQEmo7Lfp6MVeO\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.204.100, 74.125.204.138, 74.125.204.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.204.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0o-4k-docs.googleusercontent.com/docs/securesc/t8938fetd95pvvvmfoh0le2b8333ontt/7kvoq9us7su7ljt9fgudu5f0ct30ppl6/1594322100000/06930042168325031160/08433013916610211556Z/1plApL6qmdHtNNP3OXgJQEmo7Lfp6MVeO?e=download [following]\n",
            "--2020-07-09 19:15:57--  https://doc-0o-4k-docs.googleusercontent.com/docs/securesc/t8938fetd95pvvvmfoh0le2b8333ontt/7kvoq9us7su7ljt9fgudu5f0ct30ppl6/1594322100000/06930042168325031160/08433013916610211556Z/1plApL6qmdHtNNP3OXgJQEmo7Lfp6MVeO?e=download\n",
            "Resolving doc-0o-4k-docs.googleusercontent.com (doc-0o-4k-docs.googleusercontent.com)... 74.125.204.132, 2404:6800:4008:c04::84\n",
            "Connecting to doc-0o-4k-docs.googleusercontent.com (doc-0o-4k-docs.googleusercontent.com)|74.125.204.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=kkqputa47opl8&continue=https://doc-0o-4k-docs.googleusercontent.com/docs/securesc/t8938fetd95pvvvmfoh0le2b8333ontt/7kvoq9us7su7ljt9fgudu5f0ct30ppl6/1594322100000/06930042168325031160/08433013916610211556Z/1plApL6qmdHtNNP3OXgJQEmo7Lfp6MVeO?e%3Ddownload&hash=su2cgulgmdi7gdn9k9dbmhltm3iueh85 [following]\n",
            "--2020-07-09 19:15:57--  https://docs.google.com/nonceSigner?nonce=kkqputa47opl8&continue=https://doc-0o-4k-docs.googleusercontent.com/docs/securesc/t8938fetd95pvvvmfoh0le2b8333ontt/7kvoq9us7su7ljt9fgudu5f0ct30ppl6/1594322100000/06930042168325031160/08433013916610211556Z/1plApL6qmdHtNNP3OXgJQEmo7Lfp6MVeO?e%3Ddownload&hash=su2cgulgmdi7gdn9k9dbmhltm3iueh85\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.204.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-0o-4k-docs.googleusercontent.com/docs/securesc/t8938fetd95pvvvmfoh0le2b8333ontt/7kvoq9us7su7ljt9fgudu5f0ct30ppl6/1594322100000/06930042168325031160/08433013916610211556Z/1plApL6qmdHtNNP3OXgJQEmo7Lfp6MVeO?e=download&nonce=kkqputa47opl8&user=08433013916610211556Z&hash=9esbaugfnu2jnlkdv1fjqi4t538b7md9 [following]\n",
            "--2020-07-09 19:15:58--  https://doc-0o-4k-docs.googleusercontent.com/docs/securesc/t8938fetd95pvvvmfoh0le2b8333ontt/7kvoq9us7su7ljt9fgudu5f0ct30ppl6/1594322100000/06930042168325031160/08433013916610211556Z/1plApL6qmdHtNNP3OXgJQEmo7Lfp6MVeO?e=download&nonce=kkqputa47opl8&user=08433013916610211556Z&hash=9esbaugfnu2jnlkdv1fjqi4t538b7md9\n",
            "Connecting to doc-0o-4k-docs.googleusercontent.com (doc-0o-4k-docs.googleusercontent.com)|74.125.204.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘data/rudrec_annotated/rudrec.zip’\n",
            "\n",
            "data/rudrec_annotat     [ <=>                ]  14.03M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2020-07-09 19:15:58 (226 MB/s) - ‘data/rudrec_annotated/rudrec.zip’ saved [14712824]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbzru4qOolG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q data/rudrec_annotated/rudrec.zip -d data/rudrec_annotated/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IRA7xUyGZN8",
        "colab_type": "text"
      },
      "source": [
        "\"otzovik_reviews_formatting.py\" script tokenizes reviews into sentences and splits the data into train, test, and dev sets.\n",
        "\n",
        "You can use n_splits > 1 for cross-validation data split. n_splits=1 corresponds to a simple splitting of data into training, validation, and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQJLYKJGp6sH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "1ab22aaa-9045-454d-db97-8d45bcc1fec8"
      },
      "source": [
        "%cd /content/med_project/bert_multilabel/formatting/\n",
        "!python otzovik_reviews_formatting.py \\\n",
        "--reviews_dir=/content/data/rudrec_annotated/annotation \\\n",
        "--output_dir=/content/data/rudrec_annotated/sentences \\\n",
        "--n_splits=1\n",
        "!ls /content/data/rudrec_annotated/sentences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/med_project/bert_multilabel/formatting\n",
            "dev.csv  test.csv  train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wsY2a_eYbfg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "fe5d9fe5-5fed-4f01-c65e-fd12acebacfd"
      },
      "source": [
        "%cd /content\n",
        "import codecs\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import modeling\n",
        "import optimization\n",
        "import tokenization\n",
        "from bert_preprocessing import create_examples, file_based_convert_examples_to_features, \\\n",
        "    convert_examples_to_features\n",
        "from multilabel_bert import file_based_input_fn_builder, create_model, model_fn_builder, \\\n",
        "input_fn_builder, create_output, predict, get_estimator, train_and_evaluate"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "WARNING:tensorflow:From /content/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03O4isf_Ybfs",
        "colab_type": "text"
      },
      "source": [
        "###Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InL-9PbT4Ww2",
        "colab_type": "text"
      },
      "source": [
        "*Do not forget to set an appropriate BERT base dir here*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zs2602dyYbft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_dir  = r\"data/rudrec_annotated/sentences\"\n",
        "# NOT FINE-TUNED model\n",
        "base_bert_dir = r\"bert_models/multilingual_russian_reviews_finetuned/\"\n",
        "# FINE-TUNED model\n",
        "# base_bert_dir = r\"bert_models/RuDR_classification_finetuned/\"\n",
        "bert_vocab_path = os.path.join(base_bert_dir, \"vocab.txt\")\n",
        "bert_init_chkpnt_path = os.path.join(base_bert_dir, \"bert_model.ckpt\")\n",
        "bert_config_path = os.path.join(base_bert_dir, \"bert_config.json\")\n",
        "\n",
        "batch_size = 16\n",
        "num_train_epochs = 5\n",
        "warmup_proportion = 0.1\n",
        "max_seq_length = 128\n",
        "learning_rate = 2e-5\n",
        "save_summary_steps = 500\n",
        "# Besides the file of test predictions, this directory\n",
        "# will also contain checkpoints of fine-tuned BERT \n",
        "output_dir = r\"results/\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "predicted_proba_filename = \"predicted_labels.csv\"\n",
        "\n",
        "# Number of classes\n",
        "NUM_LABELS = 5\n",
        "# The column with this name must exist in test data.\n",
        "text_column_name = 'sentences'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iijC-AzwYbfy",
        "colab_type": "text"
      },
      "source": [
        "### Training\n",
        "Validation loss and accuracy for all classes is saved in f\"{output_dir}/eval_results.txt\" (path parameters are initialized at \"Parameters\" section). \n",
        "\n",
        "The first column of csv file must contain document's text. The next NUM_LABELS columns are binary columns of class correspondence.  test_df should have the same structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jptSTacdYbfz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "a153ec7b-fcbd-4445-f9c7-d92672e0808a"
      },
      "source": [
        "# Change paths if needed\n",
        "train_df = pd.read_csv(os.path.join(corpus_dir, \"train.csv\"), encoding=\"utf-8\")\n",
        "dev_df = pd.read_csv(os.path.join(corpus_dir, \"dev.csv\"), encoding=\"utf-8\")\n",
        "\n",
        "train_examples = create_examples(train_df)\n",
        "eval_examples = create_examples(dev_df)\n",
        "# Model is saved and evaluated every epoch. It might be too frequent, change it.\n",
        "num_train_steps = int(len(train_examples) / batch_size * num_train_epochs)\n",
        "num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
        "num_steps_in_epoch = int(len(train_examples) / batch_size * num_train_epochs) // num_train_epochs\n",
        "save_checkpoints_steps = num_steps_in_epoch\n",
        "print(f\"Train dataframe, examples: {train_df.shape[0]}\")\n",
        "print(train_df.head())\n",
        "print(f\"Dev dataframe, examples: {dev_df.shape[0]}\")\n",
        "dev_df.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train dataframe, examples: 1627\n",
            "                                           sentences  ...  sentence_id\n",
            "0                                  Целлюлоза и мята?  ...            4\n",
            "1  Прошлогодняя статистика по заболеваемости ОРВИ...  ...            5\n",
            "2  Общее впечатление : Хорошее средство ,успокоит...  ...            8\n",
            "3  Она недорогая, простая в применении - всего ли...  ...            3\n",
            "4  Кстати, моя родственница делала акцент, что ей...  ...            5\n",
            "\n",
            "[5 rows x 9 columns]\n",
            "Dev dataframe, examples: 181\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>EF</th>\n",
              "      <th>INF</th>\n",
              "      <th>ADR</th>\n",
              "      <th>DI</th>\n",
              "      <th>Finding</th>\n",
              "      <th>annotation</th>\n",
              "      <th>review_id</th>\n",
              "      <th>sentence_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Уже после первой таблетки зуб прошел.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>EF[5]|DI[3]</td>\n",
              "      <td>1086939</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Якобы они менее аллергичны, а мой ребёнок к ал...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Finding[3]</td>\n",
              "      <td>1268796</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>встала я только на утро, правда вот голова был...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ADR[5]</td>\n",
              "      <td>594839</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Кроме гриппа, согласно инструкции, Амизон прим...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Finding[4]</td>\n",
              "      <td>1484511</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Первым было Аллокин проколола 3 укола и на 6 м...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>EF[9]|DI[6]</td>\n",
              "      <td>2653511</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           sentences  ...  sentence_id\n",
              "0              Уже после первой таблетки зуб прошел.  ...           11\n",
              "1  Якобы они менее аллергичны, а мой ребёнок к ал...  ...            3\n",
              "2  встала я только на утро, правда вот голова был...  ...            2\n",
              "3  Кроме гриппа, согласно инструкции, Амизон прим...  ...            3\n",
              "4  Первым было Аллокин проколола 3 укола и на 6 м...  ...            2\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBRmxrkcYbf4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "01f6089c-ccf5-412d-85e2-e3ece45142b4"
      },
      "source": [
        "# Creating tokenizer\n",
        "tokenizer = tokenization.FullTokenizer(\n",
        "    vocab_file=bert_vocab_path, do_lower_case=True)\n",
        "# Definition of estimator's config\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=output_dir,\n",
        "    save_summary_steps=save_summary_steps,\n",
        "    keep_checkpoint_max=1,\n",
        "    save_checkpoints_steps=save_checkpoints_steps)\n",
        "# Loading config of pretrained Bert model\n",
        "bert_config = modeling.BertConfig.from_json_file(bert_config_path)\n",
        "\n",
        "model_fn = model_fn_builder(\n",
        "    bert_config=bert_config,\n",
        "    num_labels=NUM_LABELS ,\n",
        "    init_checkpoint=bert_init_chkpnt_path,\n",
        "    learning_rate=learning_rate,\n",
        "    num_train_steps=num_train_steps,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    use_tpu=False,\n",
        "    use_one_hot_embeddings=False)\n",
        "\n",
        "estimator = get_estimator(model_fn=model_fn, run_config=run_config, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'results/', '_tf_random_seed': None, '_save_summary_steps': 500, '_save_checkpoints_steps': 101, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fbc8c7014e0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T55pxQAYEM7_",
        "colab_type": "text"
      },
      "source": [
        "The next cell activates a training loop. The model makes checkpoints occasionally. Each checkpoint is followed by the assessment of validation accuracies for each label and loss (see log lines beginning with \"Saving dict for global step X: 0 = <label 0 accuracy>, 1 = <label 1 accuracy>,...\").  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg4-otbnYbf9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c4f1a4f-f815-44af-cad1-d4400adcdd4d"
      },
      "source": [
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "eval_steps = None\n",
        "train_and_evaluate(train_examples, eval_examples, max_seq_length, estimator, tokenizer, batch_size, eval_steps,\n",
        "                   num_train_steps, output_dir, num_labels=NUM_LABELS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/bert_preprocessing.py:257: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "INFO:tensorflow:***** Running training *****\n",
            "INFO:tensorflow:  Num examples = 1627\n",
            "INFO:tensorflow:  Batch size = 16\n",
            "INFO:tensorflow:  Num steps = 508\n",
            "WARNING:tensorflow:From /content/multilabel_bert.py:21: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "Beginning Training!\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 101 or save_checkpoints_secs None.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /content/multilabel_bert.py:57: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "WARNING:tensorflow:Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fbc8d507d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING: Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fbc8d507d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING:tensorflow:From /content/multilabel_bert.py:30: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/multilabel_bert.py:37: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From /content/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(16, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(16, 5), dtype=float32)\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "WARNING:tensorflow:From /content/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/multilabel_bert.py:172: The name tf.train.LoggingTensorHook is deprecated. Please use tf.estimator.LoggingTensorHook instead.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into results/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.68223256, step = 0\n",
            "INFO:tensorflow:accuracy = 0.6, loss = 0.68223256\n",
            "INFO:tensorflow:accuracy = 0.7, loss = 0.63973635 (18.121 sec)\n",
            "INFO:tensorflow:accuracy = 0.7291667, loss = 0.5400755 (9.443 sec)\n",
            "INFO:tensorflow:accuracy = 0.753125, loss = 0.44924298 (9.415 sec)\n",
            "INFO:tensorflow:accuracy = 0.7775, loss = 0.3538579 (9.512 sec)\n",
            "INFO:tensorflow:accuracy = 0.78333336, loss = 0.4013226 (9.425 sec)\n",
            "INFO:tensorflow:accuracy = 0.79642856, loss = 0.34640187 (9.551 sec)\n",
            "INFO:tensorflow:accuracy = 0.80625, loss = 0.29555416 (9.521 sec)\n",
            "INFO:tensorflow:accuracy = 0.81666666, loss = 0.2933131 (9.581 sec)\n",
            "INFO:tensorflow:accuracy = 0.82625, loss = 0.22147813 (9.498 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 101 into results/model.ckpt.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "WARNING:tensorflow:Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fbc1cf7e1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING: Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fbc1cf7e1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "WARNING:tensorflow:From /content/multilabel_bert.py:191: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "WARNING:tensorflow:From /content/multilabel_bert.py:193: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-09T19:22:55Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from results/model.ckpt-101\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:accuracy = 0.85, loss = 0.40704465\n",
            "INFO:tensorflow:accuracy = 0.8375, loss = 0.29026535 (1.170 sec)\n",
            "INFO:tensorflow:accuracy = 0.85833335, loss = 0.32544264 (0.579 sec)\n",
            "INFO:tensorflow:accuracy = 0.853125, loss = 0.3544681 (0.561 sec)\n",
            "INFO:tensorflow:accuracy = 0.8575, loss = 0.29754773 (0.586 sec)\n",
            "INFO:tensorflow:accuracy = 0.85833335, loss = 0.30594683 (0.558 sec)\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-09-19:23:01\n",
            "INFO:tensorflow:Saving dict for global step 101: 0 = 0.8720452, 1 = 0.9513385, 2 = 0.89925975, 3 = 0.87688863, 4 = 0.75824964, eval_loss = 0.32335532, global_step = 101, loss = 0.31035393\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 101: results/model.ckpt-101\n",
            "INFO:tensorflow:global_step/sec: 0.678242\n",
            "INFO:tensorflow:loss = 0.28071588, step = 100 (147.441 sec)\n",
            "INFO:tensorflow:accuracy = 0.8329545, loss = 0.28071588 (53.374 sec)\n",
            "INFO:tensorflow:accuracy = 0.84270835, loss = 0.19832103 (9.563 sec)\n",
            "INFO:tensorflow:accuracy = 0.8432692, loss = 0.35832942 (9.583 sec)\n",
            "INFO:tensorflow:accuracy = 0.8464286, loss = 0.3274444 (9.579 sec)\n",
            "INFO:tensorflow:accuracy = 0.8516667, loss = 0.186987 (9.519 sec)\n",
            "INFO:tensorflow:accuracy = 0.8570312, loss = 0.1468441 (9.564 sec)\n",
            "INFO:tensorflow:accuracy = 0.8632353, loss = 0.14048131 (9.557 sec)\n",
            "INFO:tensorflow:accuracy = 0.8659722, loss = 0.24554832 (9.530 sec)\n",
            "INFO:tensorflow:accuracy = 0.86973685, loss = 0.20917186 (9.431 sec)\n",
            "INFO:tensorflow:accuracy = 0.874375, loss = 0.1370795 (9.492 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.04905\n",
            "INFO:tensorflow:loss = 0.19155288, step = 200 (95.324 sec)\n",
            "INFO:tensorflow:accuracy = 0.8767857, loss = 0.19155288 (9.508 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 202 into results/model.ckpt.\n",
            "WARNING:tensorflow:Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fbc1cf7e400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING: Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fbc1cf7e400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-09T19:25:09Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from results/model.ckpt-202\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:accuracy = 0.8375, loss = 0.36699456\n",
            "INFO:tensorflow:accuracy = 0.88125, loss = 0.2106227 (1.188 sec)\n",
            "INFO:tensorflow:accuracy = 0.87916666, loss = 0.25038338 (0.587 sec)\n",
            "INFO:tensorflow:accuracy = 0.878125, loss = 0.31783968 (0.553 sec)\n",
            "INFO:tensorflow:accuracy = 0.8725, loss = 0.3945853 (0.574 sec)\n",
            "INFO:tensorflow:accuracy = 0.87291664, loss = 0.3216017 (0.549 sec)\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-09-19:25:16\n",
            "INFO:tensorflow:Saving dict for global step 202: 0 = 0.90441936, 1 = 0.9378403, 2 = 0.93497396, 3 = 0.9140845, 4 = 0.8443328, eval_loss = 0.29216865, global_step = 202, loss = 0.2805927\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 202: results/model.ckpt-202\n",
            "INFO:tensorflow:accuracy = 0.88125, loss = 0.14802358 (47.038 sec)\n",
            "INFO:tensorflow:accuracy = 0.8853261, loss = 0.11599381 (9.423 sec)\n",
            "INFO:tensorflow:accuracy = 0.8880208, loss = 0.14768443 (9.424 sec)\n",
            "INFO:tensorflow:accuracy = 0.891, loss = 0.12281481 (9.502 sec)\n",
            "INFO:tensorflow:accuracy = 0.8942308, loss = 0.08381827 (9.483 sec)\n",
            "INFO:tensorflow:accuracy = 0.8972222, loss = 0.12483604 (9.496 sec)\n",
            "INFO:tensorflow:accuracy = 0.89910716, loss = 0.18026675 (9.477 sec)\n",
            "INFO:tensorflow:accuracy = 0.90215516, loss = 0.07728271 (9.544 sec)\n",
            "INFO:tensorflow:accuracy = 0.90375, loss = 0.14651462 (9.472 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.755461\n",
            "INFO:tensorflow:loss = 0.07795383, step = 300 (132.369 sec)\n",
            "INFO:tensorflow:accuracy = 0.90645164, loss = 0.07795383 (9.510 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 303 into results/model.ckpt.\n",
            "WARNING:tensorflow:Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fbc19247bf8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING: Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fbc19247bf8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-09T19:27:22Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from results/model.ckpt-303\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:accuracy = 0.8625, loss = 0.37506226\n",
            "INFO:tensorflow:accuracy = 0.88125, loss = 0.25549477 (1.243 sec)\n",
            "INFO:tensorflow:accuracy = 0.8875, loss = 0.3025479 (0.566 sec)\n",
            "INFO:tensorflow:accuracy = 0.884375, loss = 0.2982058 (0.559 sec)\n",
            "INFO:tensorflow:accuracy = 0.875, loss = 0.35236305 (0.555 sec)\n",
            "INFO:tensorflow:accuracy = 0.87708336, loss = 0.29234648 (0.555 sec)\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-09-19:27:30\n",
            "INFO:tensorflow:Saving dict for global step 303: 0 = 0.9403048, 1 = 0.94793564, 2 = 0.92907166, 3 = 0.89609474, 4 = 0.87589663, eval_loss = 0.29682317, global_step = 303, loss = 0.28284436\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 303: results/model.ckpt-303\n",
            "INFO:tensorflow:accuracy = 0.9082031, loss = 0.1390295 (47.118 sec)\n",
            "INFO:tensorflow:accuracy = 0.9102273, loss = 0.09857717 (9.531 sec)\n",
            "INFO:tensorflow:accuracy = 0.9102941, loss = 0.19075516 (9.540 sec)\n",
            "INFO:tensorflow:accuracy = 0.9121429, loss = 0.099677585 (9.530 sec)\n",
            "INFO:tensorflow:accuracy = 0.9138889, loss = 0.10230452 (9.515 sec)\n",
            "INFO:tensorflow:accuracy = 0.91486484, loss = 0.13859078 (9.532 sec)\n",
            "INFO:tensorflow:accuracy = 0.91611844, loss = 0.1420426 (9.505 sec)\n",
            "INFO:tensorflow:accuracy = 0.9173077, loss = 0.121958 (9.540 sec)\n",
            "INFO:tensorflow:accuracy = 0.9190625, loss = 0.07094169 (9.491 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.753113\n",
            "INFO:tensorflow:loss = 0.04729419, step = 400 (132.782 sec)\n",
            "INFO:tensorflow:accuracy = 0.9210366, loss = 0.04729419 (9.478 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 404 into results/model.ckpt.\n",
            "WARNING:tensorflow:Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fbc190372f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING: Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fbc190372f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-09T19:29:36Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from results/model.ckpt-404\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:accuracy = 0.875, loss = 0.36822483\n",
            "INFO:tensorflow:accuracy = 0.8875, loss = 0.32607347 (1.212 sec)\n",
            "INFO:tensorflow:accuracy = 0.89166665, loss = 0.27407584 (0.564 sec)\n",
            "INFO:tensorflow:accuracy = 0.8875, loss = 0.3184616 (0.565 sec)\n",
            "INFO:tensorflow:accuracy = 0.8775, loss = 0.35458833 (0.556 sec)\n",
            "INFO:tensorflow:accuracy = 0.88125, loss = 0.2685861 (0.558 sec)\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-09-19:29:43\n",
            "INFO:tensorflow:Saving dict for global step 404: 0 = 0.9375642, 1 = 0.95508164, 2 = 0.92757094, 3 = 0.90749043, 4 = 0.8911406, eval_loss = 0.28541788, global_step = 404, loss = 0.27179876\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 404: results/model.ckpt-404\n",
            "INFO:tensorflow:accuracy = 0.92202383, loss = 0.10756572 (46.942 sec)\n",
            "INFO:tensorflow:accuracy = 0.9238372, loss = 0.06150924 (9.563 sec)\n",
            "INFO:tensorflow:accuracy = 0.92556816, loss = 0.05189835 (9.487 sec)\n",
            "INFO:tensorflow:accuracy = 0.92638886, loss = 0.13439384 (9.532 sec)\n",
            "INFO:tensorflow:accuracy = 0.9279891, loss = 0.045328222 (9.476 sec)\n",
            "INFO:tensorflow:accuracy = 0.92898935, loss = 0.12705484 (9.515 sec)\n",
            "INFO:tensorflow:accuracy = 0.9299479, loss = 0.0723535 (9.498 sec)\n",
            "INFO:tensorflow:accuracy = 0.93137753, loss = 0.038094644 (9.501 sec)\n",
            "INFO:tensorflow:accuracy = 0.9325, loss = 0.084837325 (9.464 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.728579\n",
            "INFO:tensorflow:loss = 0.035361312, step = 500 (137.254 sec)\n",
            "INFO:tensorflow:accuracy = 0.9338235, loss = 0.035361312 (14.277 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 505 into results/model.ckpt.\n",
            "WARNING:tensorflow:Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fbc1ce83a60> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING: Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fbc1ce83a60> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-09T19:31:56Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from results/model.ckpt-505\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:accuracy = 0.8875, loss = 0.34671527\n",
            "INFO:tensorflow:accuracy = 0.89375, loss = 0.32132912 (1.194 sec)\n",
            "INFO:tensorflow:accuracy = 0.89166665, loss = 0.2855365 (0.571 sec)\n",
            "INFO:tensorflow:accuracy = 0.8875, loss = 0.3217002 (0.565 sec)\n",
            "INFO:tensorflow:accuracy = 0.8775, loss = 0.34242088 (0.568 sec)\n",
            "INFO:tensorflow:accuracy = 0.8833333, loss = 0.25270766 (0.560 sec)\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-09-19:32:03\n",
            "INFO:tensorflow:Saving dict for global step 505: 0 = 0.9380781, 1 = 0.9595055, 2 = 0.93267304, 3 = 0.90621, 4 = 0.90297705, eval_loss = 0.28276157, global_step = 505, loss = 0.2688256\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 505: results/model.ckpt-505\n",
            "INFO:tensorflow:Saving checkpoints for 508 into results/model.ckpt.\n",
            "WARNING:tensorflow:Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fbc1b4fba60> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING: Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fbc1b4fba60> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-09T19:32:46Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from results/model.ckpt-508\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:accuracy = 0.8875, loss = 0.34677035\n",
            "INFO:tensorflow:accuracy = 0.89375, loss = 0.32121193 (1.204 sec)\n",
            "INFO:tensorflow:accuracy = 0.89166665, loss = 0.2855649 (0.565 sec)\n",
            "INFO:tensorflow:accuracy = 0.8875, loss = 0.32166943 (0.570 sec)\n",
            "INFO:tensorflow:accuracy = 0.8775, loss = 0.34247002 (0.554 sec)\n",
            "INFO:tensorflow:accuracy = 0.8833333, loss = 0.25273138 (0.559 sec)\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-09-19:32:53\n",
            "INFO:tensorflow:Saving dict for global step 508: 0 = 0.9380781, 1 = 0.9595055, 2 = 0.93267304, 3 = 0.906146, 4 = 0.90333575, eval_loss = 0.28277546, global_step = 508, loss = 0.2688374\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 508: results/model.ckpt-508\n",
            "INFO:tensorflow:Loss for final step: 0.072655186.\n",
            "Training took time  0:13:18.859803\n",
            "WARNING:tensorflow:Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fbc1b30b620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING: Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fbc1b30b620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-09T19:32:57Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from results/model.ckpt-508\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:accuracy = 0.8875, loss = 0.34677035\n",
            "INFO:tensorflow:accuracy = 0.89375, loss = 0.32121193 (1.237 sec)\n",
            "INFO:tensorflow:accuracy = 0.89166665, loss = 0.2855649 (0.565 sec)\n",
            "INFO:tensorflow:accuracy = 0.8875, loss = 0.32166943 (0.557 sec)\n",
            "INFO:tensorflow:accuracy = 0.8775, loss = 0.34247002 (0.554 sec)\n",
            "INFO:tensorflow:accuracy = 0.8833333, loss = 0.25273138 (0.554 sec)\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-09-19:33:04\n",
            "INFO:tensorflow:Saving dict for global step 508: 0 = 0.9380781, 1 = 0.9595055, 2 = 0.93267304, 3 = 0.906146, 4 = 0.90333575, eval_loss = 0.28277546, global_step = 508, loss = 0.2688374\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 508: results/model.ckpt-508\n",
            "INFO:tensorflow:***** Eval results *****\n",
            "INFO:tensorflow:  0 = 0.9380781\n",
            "INFO:tensorflow:  1 = 0.9595055\n",
            "INFO:tensorflow:  2 = 0.93267304\n",
            "INFO:tensorflow:  3 = 0.906146\n",
            "INFO:tensorflow:  4 = 0.90333575\n",
            "INFO:tensorflow:  eval_loss = 0.28277546\n",
            "INFO:tensorflow:  global_step = 508\n",
            "INFO:tensorflow:  loss = 0.2688374\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMAN5HirYbgC",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbNty34lYbgJ",
        "colab_type": "text"
      },
      "source": [
        "####Initializing estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRUfEnbeYbgK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "b6287064-1231-4496-d4bb-0c16ebec5b4f"
      },
      "source": [
        "train_examples = None\n",
        "num_train_steps = None\n",
        "num_warmup_steps = None\n",
        "save_checkpoints_steps = 1000\n",
        "\n",
        "# Creating tokenizer\n",
        "tokenizer = tokenization.FullTokenizer(\n",
        "    vocab_file=bert_vocab_path, do_lower_case=True)\n",
        "# Definition of estimator's config\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=output_dir,\n",
        "    save_summary_steps=save_summary_steps,\n",
        "    keep_checkpoint_max=1,\n",
        "    save_checkpoints_steps=save_checkpoints_steps)\n",
        "# Loading config of pretrained Bert model\n",
        "bert_config = modeling.BertConfig.from_json_file(bert_config_path)\n",
        "\n",
        "model_fn = model_fn_builder(\n",
        "    bert_config=bert_config,\n",
        "    num_labels=NUM_LABELS ,\n",
        "    init_checkpoint=bert_init_chkpnt_path,\n",
        "    learning_rate=learning_rate,\n",
        "    num_train_steps=num_train_steps,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    use_tpu=False,\n",
        "    use_one_hot_embeddings=False)\n",
        "\n",
        "estimator = get_estimator(model_fn=model_fn, run_config=run_config, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'results/', '_tf_random_seed': None, '_save_summary_steps': 500, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fbc190f9128>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HltkaoRUYbgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change path if needed\n",
        "test_df = pd.read_csv(os.path.join(corpus_dir, \"test.csv\"), encoding=\"utf-8\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IewGLgCK8kIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_names = {\"p_label_1\" : \"EF\", \"p_label_2\" : \"INF\", \"p_label_3\" : \"ADR\", \"p_label_4\" : \"DI\", \"p_label_5\" : \"Finding\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "5IxE3nJGYbgS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "598c649a-83cb-4c06-9358-120dee04d95a"
      },
      "source": [
        "output_df = predict(test_df, estimator, tokenizer, max_seq_length, num_labels=NUM_LABELS)\n",
        "\n",
        "resulting_df = test_df[text_column_name]\n",
        "resulting_df = pd.concat([test_df, output_df], axis=1)\n",
        "resulting_df.to_csv(os.path.join(output_dir, predicted_proba_filename), index=False)\n",
        "resulting_df.rename(columns=label_names, inplace=True)\n",
        "resulting_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Predictions!\n",
            "Prediction took time  0:00:00.000366\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "mode: infer probabilities: Tensor(\"loss/Sigmoid:0\", shape=(?, 5), dtype=float32)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from results/model.ckpt-508\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>EF</th>\n",
              "      <th>INF</th>\n",
              "      <th>ADR</th>\n",
              "      <th>DI</th>\n",
              "      <th>Finding</th>\n",
              "      <th>annotation</th>\n",
              "      <th>review_id</th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>EF</th>\n",
              "      <th>INF</th>\n",
              "      <th>ADR</th>\n",
              "      <th>DI</th>\n",
              "      <th>Finding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Но ребенок заболевал не зависимо от того прини...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>INF[4]</td>\n",
              "      <td>273783</td>\n",
              "      <td>7</td>\n",
              "      <td>0.015046</td>\n",
              "      <td>0.084106</td>\n",
              "      <td>0.011273</td>\n",
              "      <td>0.009133</td>\n",
              "      <td>0.016036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>И никуда моя тревожность не исчезла.</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>INF[2]|DI[3]</td>\n",
              "      <td>2403676</td>\n",
              "      <td>4</td>\n",
              "      <td>0.062887</td>\n",
              "      <td>0.972314</td>\n",
              "      <td>0.036536</td>\n",
              "      <td>0.924222</td>\n",
              "      <td>0.072481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>А позже выяснилось, что у ребёнка просто резал...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>DI[5]</td>\n",
              "      <td>624086</td>\n",
              "      <td>9</td>\n",
              "      <td>0.020808</td>\n",
              "      <td>0.011523</td>\n",
              "      <td>0.026656</td>\n",
              "      <td>0.984198</td>\n",
              "      <td>0.045432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Так нас продержали на сиропчиках, по типу брон...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>DI[2]</td>\n",
              "      <td>2533930</td>\n",
              "      <td>10</td>\n",
              "      <td>0.004549</td>\n",
              "      <td>0.074050</td>\n",
              "      <td>0.256111</td>\n",
              "      <td>0.956854</td>\n",
              "      <td>0.155523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Так вот матирующего эффекта я не заметила, и с...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>INF[2]|DI[1]</td>\n",
              "      <td>2523468</td>\n",
              "      <td>3</td>\n",
              "      <td>0.790932</td>\n",
              "      <td>0.869061</td>\n",
              "      <td>0.022939</td>\n",
              "      <td>0.970730</td>\n",
              "      <td>0.059775</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           sentences  EF  ...        DI   Finding\n",
              "0  Но ребенок заболевал не зависимо от того прини...   0  ...  0.009133  0.016036\n",
              "1               И никуда моя тревожность не исчезла.   0  ...  0.924222  0.072481\n",
              "2  А позже выяснилось, что у ребёнка просто резал...   0  ...  0.984198  0.045432\n",
              "3  Так нас продержали на сиропчиках, по типу брон...   0  ...  0.956854  0.155523\n",
              "4  Так вот матирующего эффекта я не заметила, и с...   0  ...  0.970730  0.059775\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5Wt7gShYbgW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "METRICS = {\"Precision\": precision_score, \"Recall\": recall_score,\n",
        "           \"F-score\": f1_score, }\n",
        "threshold=0.5\n",
        "average='binary'\n",
        "pos_label=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_StFHN1lYbga",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "4897250e-66e1-4632-92f3-c1ec26ee0b25"
      },
      "source": [
        "predicted_probs_pos_end = resulting_df.shape[1]\n",
        "predicted_probs_pos_start = predicted_probs_pos_end - NUM_LABELS\n",
        "columns = resulting_df.columns\n",
        "labels = columns[1: 1 + NUM_LABELS]\n",
        "results_numpy = resulting_df.values.transpose()\n",
        "all_true_labels = results_numpy[1: 1 + NUM_LABELS].astype(int)\n",
        "all_pred_probs = results_numpy[predicted_probs_pos_start: predicted_probs_pos_end]\n",
        "all_pred_labels = (all_pred_probs >= threshold).astype(int)\n",
        "for i in range(NUM_LABELS):\n",
        "    class_true_labels = all_true_labels[i]\n",
        "    class_pred_labels = all_pred_labels[i]\n",
        "    label_name = labels[i]\n",
        "    print(i, label_name)\n",
        "    for metric_name, metric in METRICS.items():\n",
        "        score = metric(y_true=class_true_labels, y_pred=class_pred_labels, labels=labels, )\n",
        "        print(f\"\\t{metric_name} : {score}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 EF\n",
            "\tPrecision : 0.8157894736842105\n",
            "\tRecall : 0.7560975609756098\n",
            "\tF-score : 0.7848101265822786\n",
            "1 INF\n",
            "\tPrecision : 0.7894736842105263\n",
            "\tRecall : 0.7377049180327869\n",
            "\tF-score : 0.7627118644067797\n",
            "2 ADR\n",
            "\tPrecision : 0.7868852459016393\n",
            "\tRecall : 0.7272727272727273\n",
            "\tF-score : 0.7559055118110236\n",
            "3 DI\n",
            "\tPrecision : 0.822429906542056\n",
            "\tRecall : 0.9072164948453608\n",
            "\tF-score : 0.8627450980392157\n",
            "4 Finding\n",
            "\tPrecision : 0.5555555555555556\n",
            "\tRecall : 0.2564102564102564\n",
            "\tF-score : 0.3508771929824561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJdZ0eJG-xkb",
        "colab_type": "text"
      },
      "source": [
        "#### Preprocessing of new data and prediction of labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyR7g2Bd4rxA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "53d2224d-da9e-44ba-cec4-fe7b0d19382f"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')\n",
        "def tokenize_sentences(text, language='russian', text_column=text_column_name):\n",
        "    sentences = [sent for sent in sent_tokenize(text, language)]\n",
        "    sentences_df = pd.DataFrame(sentences, columns =[text_column], )\n",
        "    return sentences_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cCMPk9nDxLv",
        "colab_type": "text"
      },
      "source": [
        "You can upload your texts, tokenize them, and predict label probabilities for them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfSpa4yF7dVK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ac56608e-5932-4762-91f0-d3de95ff43d8"
      },
      "source": [
        "text = \"Старший ребенок часто болел, ходил в детский сад неделю, максимум две, затем на больничный. \" \\\n",
        "\"После приема действительно становилось легче, и горло меньше болело и нос не так закладывало. \" \\\n",
        "\"Могу сказать, что временное облегчение он обеспечивает, и на вкус довольно приятным оказался, даже вкусным.\"\n",
        "sentences_df = tokenize_sentences(text, language='russian', )\n",
        "sentences_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Старший ребенок часто болел, ходил в детский с...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>После приема действительно становилось легче, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Могу сказать, что временное облегчение он обес...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           sentences\n",
              "0  Старший ребенок часто болел, ходил в детский с...\n",
              "1  После приема действительно становилось легче, ...\n",
              "2  Могу сказать, что временное облегчение он обес..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WB9Btxt-Hbr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "d84ea870-7a46-4040-8299-135a9334502b"
      },
      "source": [
        "decision_threshold = 0.5\n",
        "predicted_probabilities = predict(sentences_df, estimator, tokenizer, max_seq_length, num_labels=NUM_LABELS)\n",
        "predicted_probabilities.rename(columns=label_names, inplace=True)\n",
        "predicted_labels = predicted_probabilities.applymap(lambda x: 1 if x >= decision_threshold else 0)\n",
        "\n",
        "pd.concat([sentences_df, predicted_probabilities], axis=1).head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Predictions!\n",
            "Prediction took time  0:00:00.000020\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:num_labels:5;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 5), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 5), dtype=float32)\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "mode: infer probabilities: Tensor(\"loss/Sigmoid:0\", shape=(?, 5), dtype=float32)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from results/model.ckpt-508\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>EF</th>\n",
              "      <th>INF</th>\n",
              "      <th>ADR</th>\n",
              "      <th>DI</th>\n",
              "      <th>Finding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Старший ребенок часто болел, ходил в детский с...</td>\n",
              "      <td>0.004685</td>\n",
              "      <td>0.009316</td>\n",
              "      <td>0.009434</td>\n",
              "      <td>0.285730</td>\n",
              "      <td>0.024863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>После приема действительно становилось легче, ...</td>\n",
              "      <td>0.983669</td>\n",
              "      <td>0.058321</td>\n",
              "      <td>0.063091</td>\n",
              "      <td>0.959294</td>\n",
              "      <td>0.044858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Могу сказать, что временное облегчение он обес...</td>\n",
              "      <td>0.978817</td>\n",
              "      <td>0.044704</td>\n",
              "      <td>0.042769</td>\n",
              "      <td>0.043631</td>\n",
              "      <td>0.031108</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           sentences  ...   Finding\n",
              "0  Старший ребенок часто болел, ходил в детский с...  ...  0.024863\n",
              "1  После приема действительно становилось легче, ...  ...  0.044858\n",
              "2  Могу сказать, что временное облегчение он обес...  ...  0.031108\n",
              "\n",
              "[3 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akt7oXLYd5hc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "852a9180-0a03-4c7c-96c2-a2b2efe5eb87"
      },
      "source": [
        "predicted_labels = predicted_probabilities.applymap(lambda x: 1 if x >= decision_threshold else 0)\n",
        "resulting_df = pd.concat([sentences_df, predicted_labels], axis=1)\n",
        "\n",
        "resulting_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>EF</th>\n",
              "      <th>INF</th>\n",
              "      <th>ADR</th>\n",
              "      <th>DI</th>\n",
              "      <th>Finding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Старший ребенок часто болел, ходил в детский с...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>После приема действительно становилось легче, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Могу сказать, что временное облегчение он обес...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           sentences  EF  INF  ADR  DI  Finding\n",
              "0  Старший ребенок часто болел, ходил в детский с...   0    0    0   0        0\n",
              "1  После приема действительно становилось легче, ...   1    0    0   1        0\n",
              "2  Могу сказать, что временное облегчение он обес...   1    0    0   0        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE_3mMDMBV6O",
        "colab_type": "text"
      },
      "source": [
        "#### Writing predictions to JSON file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wLVg4i9-Mhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_json_path = r\"results/predicted_labels.json\"\n",
        "resulting_df.to_json(output_json_path, orient='records',)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l87Mf_sRCZdJ",
        "colab_type": "text"
      },
      "source": [
        "If you use Google Colab, you can download predictions by uncommenting and running the following lines: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrrVfbGDC3bQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import files\n",
        "# files.download(output_json_path) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}